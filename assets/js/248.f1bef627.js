(window.webpackJsonp=window.webpackJsonp||[]).push([[248],{626:function(s,t,a){"use strict";a.r(t);var r=a(26),e=Object(r.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"慢查询优化思路与案例"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#慢查询优化思路与案例"}},[s._v("#")]),s._v(" 慢查询优化思路与案例")]),s._v(" "),a("h2",{attrs:{id:"_1-建索引的几大原则"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-建索引的几大原则"}},[s._v("#")]),s._v(" 1. 建索引的几大原则")]),s._v(" "),a("ol",[a("li",[a("p",[s._v("最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询("),a("code",[s._v(">")]),s._v("、"),a("code",[s._v("<")]),s._v("、"),a("code",[s._v("between")]),s._v("、"),a("code",[s._v("like")]),s._v(")就停止匹配，比如"),a("code",[s._v("a = 1 and b = 2 and c > 3 and d = 4")]),s._v(" 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。")])]),s._v(" "),a("li",[a("p",[s._v("=和in可以乱序，比如"),a("code",[s._v("a = 1 and b = 2 and c = 3")]),s._v(" 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式")])]),s._v(" "),a("li",[a("p",[s._v("尽量选择区分度高的列作为索引，区分度的公式是"),a("code",[s._v("count(distinct col)/count(*)")]),s._v("，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。")])]),s._v(" "),a("li",[a("p",[s._v("索引列不能参与计算，保持列“干净”，比如"),a("code",[s._v("from_unixtime(create_time) = ’2014-05-29’")]),s._v("就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。")])]),s._v(" "),a("li",[a("p",[s._v("尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。")])])]),s._v(" "),a("h2",{attrs:{id:"_2-优化步骤-explain命令"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-优化步骤-explain命令"}},[s._v("#")]),s._v(" 2. 优化步骤- explain命令")]),s._v(" "),a("blockquote",[a("p",[s._v("关于explain命令相信大家并不陌生，具体用法和字段含义可以参考官网explain-output，这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。")])]),s._v(" "),a("ol",{attrs:{start:"0"}},[a("li",[a("p",[s._v("先运行看看是否真的很慢，注意设置SQL_NO_CACHE")])]),s._v(" "),a("li",[a("p",[s._v("where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高")])]),s._v(" "),a("li",[a("p",[s._v("explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）")])]),s._v(" "),a("li",[a("p",[s._v("order by limit 形式的sql语句让排序的表优先查")])]),s._v(" "),a("li",[a("p",[s._v("了解业务方使用场景")])]),s._v(" "),a("li",[a("p",[s._v("加索引时参照建索引的几大原则")])]),s._v(" "),a("li",[a("p",[s._v("观察结果，不符合预期继续从0分析")])])]),s._v(" "),a("h2",{attrs:{id:"_3-慢查询优化案例"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-慢查询优化案例"}},[s._v("#")]),s._v(" 3. 慢查询优化案例")]),s._v(" "),a("h3",{attrs:{id:"_3-1-复杂语句写法-优化sql"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-复杂语句写法-优化sql"}},[s._v("#")]),s._v(" 3.1 复杂语句写法（优化sql）")]),s._v(" "),a("p",[s._v("很多情况下，我们写SQL只是为了实现功能，这只是第一步，不同的语句书写方式对于效率往往有本质的差别，这要求我们对mysql的执行计划和索引原则有非常清楚的认识，请看下面的语句：")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("distinct")]),s._v(" cert"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("emp_id \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n   cm_log cl \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n         emp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" emp_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n         emp_cert"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" cert_id \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n         employee emp \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("left")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n         emp_certificate emp_cert \n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" emp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" emp_cert"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("emp_id \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n         emp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_deleted"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" cert \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n         cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref_table"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Employee'")]),s._v(" \n         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref_oid"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cert"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("emp_id\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("or")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n         cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref_table"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'EmpCertificate'")]),s._v(" \n         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref_oid"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cert"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cert_id\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n   cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_upd_date "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2013-11-07 15:03:00'")]),s._v(" \n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_upd_date"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2013-11-08 16:00:00'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n")])])]),a("ol",{attrs:{start:"0"}},[a("li",[a("strong",[s._v("先运行一下")]),s._v("，53条记录 1.87秒，又没有用聚合语句，比较慢")])]),s._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[s._v("53")]),s._v(" rows "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.87")]),s._v(" sec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),a("ol",[a("li",[a("strong",[s._v("explain")])])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+-------------+------------+-------+---------------------------------+-----------------------+---------+-------------------+-------+--------------------------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" select_type "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v("      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" possible_keys                   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("key")]),s._v("                   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" key_len "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" ref               "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" Extra                          "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+-------------+------------+-------+---------------------------------+-----------------------+---------+-------------------+-------+--------------------------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" cl         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" range "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" cm_log_cls_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("idx_last_upd_date "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" idx_last_upd_date     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("              "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("379")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("temporary")]),s._v("   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("derived2"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALL")]),s._v("   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("                            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("                  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("              "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("63727")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v(" buffer "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" DERIVED     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" emp        "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALL")]),s._v("   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("                            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("                  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("              "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("13317")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("                    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" DERIVED     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" emp_cert   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" ref   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" emp_certificate_empid           "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" emp_certificate_empid "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" meituanorg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("emp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("index")]),s._v("                    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+-------------+------------+-------+---------------------------------+-----------------------+---------+-------------------+-------+--------------------------------+")]),s._v("\n")])])]),a("ol",{attrs:{start:"2"}},[a("li",[a("p",[a("strong",[s._v("简述一下执行计划")]),s._v("，首先mysql根据idx_last_upd_date索引扫描cm_log表获得379条记录；然后查表扫描了63727条记录，分为两部分，derived表示构造表，也就是不存在的表，可以简单理解成是一个语句形成的结果集，后面的数字表示语句的ID。derived2表示的是ID = 2的查询构造了虚拟表，并且返回了63727条记录。我们再来看看ID = 2的语句究竟做了写什么返回了这么大量的数据，首先全表扫描employee表13317条记录，然后根据索引emp_certificate_empid关联emp_certificate表，rows = 1表示，每个关联都只锁定了一条记录，效率比较高。获得后，再和cm_log的379条记录根据规则关联。从执行过程上可以看出返回了太多的数据，返回的数据绝大部分cm_log都用不到，因为cm_log只锁定了379条记录。")])]),s._v(" "),a("li",[a("p",[a("strong",[s._v("如何优化呢")]),s._v("？可以看到我们在运行完后还是要和cm_log做join,那么我们能不能之前和cm_log做join呢？仔细分析语句不难发现，其基本思想是如果cm_log的ref_table是EmpCertificate就关联emp_certificate表，如果ref_table是Employee就关联employee表，我们完全可以拆成两部分，并用union连接起来，注意这里用union，而不用union all是因为原语句有“distinct”来得到唯一的记录，而union恰好具备了这种功能。如果原语句中没有distinct不需要去重，我们就可以直接使用union all了，因为使用union需要去重的动作，会影响SQL性能。")])])]),s._v(" "),a("p",[s._v("优化过的语句如下：")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n   emp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n   cm_log cl \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n   employee emp \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref_table "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Employee'")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref_oid "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" emp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n   cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_upd_date "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2013-11-07 15:03:00'")]),s._v(" \n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_upd_date"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2013-11-08 16:00:00'")]),s._v(" \n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" emp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_deleted "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("union")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n   emp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n   cm_log cl \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n   emp_certificate ec \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref_table "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'EmpCertificate'")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref_oid "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n   employee emp \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" emp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("emp_id  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n   cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_upd_date "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2013-11-07 15:03:00'")]),s._v(" \n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_upd_date"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2013-11-08 16:00:00'")]),s._v(" \n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" emp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_deleted "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n\n")])])]),a("ol",{attrs:{start:"4"}},[a("li",[a("p",[s._v("不需要了解业务场景，只需要改造的语句和改造之前的语句保持结果一致")])]),s._v(" "),a("li",[a("p",[s._v("现有索引可以满足，不需要建索引")])]),s._v(" "),a("li",[a("p",[s._v("用改造后的语句实验一下，只需要10ms 降低了近200倍！")])])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+--------------+------------+--------+---------------------------------+-------------------+---------+-----------------------+------+-------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" select_type  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v("      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v("   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" possible_keys                   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("key")]),s._v("               "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" key_len "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" ref                   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" Extra       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+--------------+------------+--------+---------------------------------+-------------------+---------+-----------------------+------+-------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" cl         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" range  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" cm_log_cls_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("idx_last_upd_date "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" idx_last_upd_date "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("                  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("379")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" emp        "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" eq_ref "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("                         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("           "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" meituanorg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref_oid "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("UNION")]),s._v("        "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" cl         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" range  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" cm_log_cls_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("idx_last_upd_date "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" idx_last_upd_date "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("                  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("379")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("UNION")]),s._v("        "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" ec         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" eq_ref "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("emp_certificate_empid   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("           "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" meituanorg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ref_oid "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("             "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("UNION")]),s._v("        "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" emp        "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" eq_ref "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("                         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("           "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" meituanorg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("emp_id  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("UNION")]),s._v(" RESULT "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("union1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALL")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("                            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("              "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("                  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("             "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+--------------+------------+--------+---------------------------------+-------------------+---------+-----------------------+------+-------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("53")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),s._v(" sec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])])]),a("h3",{attrs:{id:"_3-2-明确应用场景-区分度低加索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-明确应用场景-区分度低加索引"}},[s._v("#")]),s._v(" 3.2 明确应用场景（区分度低加索引）")]),s._v(" "),a("p",[s._v("举这个例子的目的在于颠覆我们对列的区分度的认知，一般上我们认为区分度越高的列，越容易锁定更少的记录，但在一些特殊的情况下，这种理论是有局限性的。")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n   stage_poi sp \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n   sp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("accurate_result"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" \n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      sp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sync_status"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("or")]),s._v(" sp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sync_status"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("or")]),s._v(" sp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sync_status"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n")])])]),a("ol",{attrs:{start:"0"}},[a("li",[a("strong",[s._v("先看看运行多长时间")]),s._v(",951条数据6.22秒，真的很慢。")])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[s._v("951")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("6.22")]),s._v(" sec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),a("ol",[a("li",[a("strong",[s._v("先explain")]),s._v("，rows达到了361万，type = ALL表明是全表扫描。")])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+-------------+-------+------+---------------+------+---------+------+---------+-------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" select_type "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" possible_keys "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("key")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" key_len "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" ref  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" Extra       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+-------------+-------+------+---------------+------+---------+------+---------+-------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SIMPLE")]),s._v("      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" sp    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALL")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("          "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3613155")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+-------------+-------+------+---------------+------+---------+------+---------+-------------+")]),s._v("\n\n  \n")])])]),a("ol",{attrs:{start:"2"}},[a("li",[a("p",[s._v("所有字段都应用查询返回记录数，因为是单表查询 0已经做过了951条。")])]),s._v(" "),a("li",[a("p",[s._v("让explain的rows 尽量逼近951。")])])]),s._v(" "),a("p",[s._v("看一下accurate_result = 1的记录数：")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("accurate_result "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" stage_poi  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("group")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" accurate_result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----------+-----------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" accurate_result "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----------+-----------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1023")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("              "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2114655")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("               "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("972815")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("               "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----------+-----------------+")]),s._v("\n")])])]),a("p",[s._v("我们看到accurate_result这个字段的区分度非常低，整个表只有-1,0,1三个值，加上索引也无法锁定特别少量的数据。")]),s._v(" "),a("p",[s._v("再看一下sync_status字段的情况：")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("sync_status "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" stage_poi  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("group")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" sync_status"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----------+-------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" sync_status "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----------+-------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("     "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3080")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3085413")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("           "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----------+-------------+")]),s._v("\n\n")])])]),a("p",[s._v("同样的区分度也很低，根据理论，也不适合建立索引。")]),s._v(" "),a("p",[s._v("问题分析到这，好像得出了这个表无法优化的结论，两个列的区分度都很低，即便加上索引也只能适应这种情况，很难做普遍性的优化，比如当sync_status 0、3分布的很平均，那么锁定记录也是百万级别的。")]),s._v(" "),a("ol",{attrs:{start:"4"}},[a("li",[a("p",[a("strong",[s._v("找业务方去沟通，看看使用场景")]),s._v("。业务方是这么来使用这个SQL语句的，每隔五分钟会扫描符合条件的数据，处理完成后把sync_status这个字段变成1,五分钟符合条件的记录数并不会太多，1000个左右。了解了业务方的使用场景后，优化这个SQL就变得简单了，因为业务方保证了数据的不平衡，如果加上索引可以过滤掉绝大部分不需要的数据。")])]),s._v(" "),a("li",[a("p",[a("strong",[s._v("根据建立索引规则")]),s._v("，使用如下语句建立索引")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" stage_poi "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("add")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("index")]),s._v(" idx_acc_status"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("accurate_result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("sync_status"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])])]),s._v(" "),a("li",[a("p",[a("strong",[s._v("观察预期结果")]),s._v(",发现只需要200ms，快了30多倍。")]),s._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[s._v("952")]),s._v(" rows "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.20")]),s._v(" sec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])])])]),s._v(" "),a("p",[s._v("我们再来回顾一下分析问题的过程，单表查询相对来说比较好优化，大部分时候只需要把where条件里面的字段依照规则加上索引就好，如果只是这种“无脑”优化的话，显然一些区分度非常低的列，不应该加索引的列也会被加上索引，这样会对插入、更新性能造成严重的影响，同时也有可能影响其它的查询语句。所以我们第4步调差SQL的使用场景非常关键，我们只有知道这个业务场景，才能更好地辅助我们更好的分析和优化查询语句。")]),s._v(" "),a("h3",{attrs:{id:"_3-3-无法优化的语句-对大数据量排序导致的问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-无法优化的语句-对大数据量排序导致的问题"}},[s._v("#")]),s._v(" 3.3 无法优化的语句(对大数据量排序导致的问题)")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("position"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("phone"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("office_phone"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("feature_info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("birthday"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("creator_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_keyperson"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("giveup_reason"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data_source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   from_unixtime"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("created_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" created_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   from_unixtime"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_modified"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" last_modified"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_modified_user_id  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n   contact c  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n   contact_branch cb \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v("  c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("contact_id  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n   branch_user bu \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v("  cb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("branch_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("branch_id \n      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  \n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n      org_emp_info oei \n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v("  oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("user_id \n         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("node_left "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2875")]),s._v(" \n         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("node_right "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10802")]),s._v(" \n         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("org_category "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("  \n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v("\n      c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("created_time "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("desc")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n")])])]),a("p",[s._v("还是几个步骤。")]),s._v(" "),a("ol",{attrs:{start:"0"}},[a("li",[a("strong",[s._v("先看语句运行多长时间")]),s._v("，10条记录用了13秒，已经不可忍受。")])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("13.06")]),s._v(" sec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),a("ol",[a("li",[a("strong",[s._v("explain")])])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+-------------+-------+--------+-------------------------------------+-------------------------+---------+--------------------------+------+----------------------------------------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" select_type "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),s._v("   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" possible_keys                       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("key")]),s._v("                     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" key_len "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" ref                      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" Extra                                        "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+-------------+-------+--------+-------------------------------------+-------------------------+---------+--------------------------+------+----------------------------------------------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SIMPLE")]),s._v("      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" oei   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" ref    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" idx_category_left_right"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("idx_data_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" idx_category_left_right "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" const                    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("8849")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("temporary")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" filesort "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SIMPLE")]),s._v("      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" bu    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" ref    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("idx_userid_status           "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" idx_userid_status       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" meituancrm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data_id   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("76")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("Using")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("index")]),s._v("                     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SIMPLE")]),s._v("      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" cb    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" ref    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" idx_branch_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("idx_contact_branch_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" idx_branch_id           "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("       "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" meituancrm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("branch_id  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("                                              "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SIMPLE")]),s._v("      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" c     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" eq_ref "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("                             "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v("                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("108")]),s._v("     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" meituancrm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("contact_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("                                              "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----+-------------+-------+--------+-------------------------------------+-------------------------+---------+--------------------------+------+----------------------------------------------+")]),s._v("\n")])])]),a("p",[s._v("从执行计划上看，mysql先查org_emp_info表扫描8849记录，再用索引idx_userid_status关联branch_user表，再用索引idx_branch_id关联contact_branch表，最后主键关联contact表。")]),s._v(" "),a("p",[s._v("rows返回的都非常少，看不到有什么异常情况。我们在看一下语句，发现后面有order by + limit组合，会不会是排序量太大搞的？于是我们简化SQL，去掉后面的order by 和 limit，看看到底用了多少记录来排序。")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n   contact c  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n   contact_branch cb \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v("  c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("contact_id  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n   branch_user bu \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v("  cb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("branch_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("branch_id \n      "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  \n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n      org_emp_info oei \n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v("  oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("user_id \n         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("node_left "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2875")]),s._v(" \n         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("node_right "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10802")]),s._v(" \n         "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("org_category "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("  \n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("778878")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("----------+")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("row")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5.19")]),s._v(" sec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])])]),a("p",[s._v("发现排序之前居然锁定了778878条记录，如果针对70万的结果集排序，将是灾难性的，怪不得这么慢，那我们能不能换个思路，先根据contact的created_time排序，再来join会不会比较快呢？")]),s._v(" "),a("p",[s._v("于是改造成下面的语句，也可以用straight_join来优化：")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("position"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("phone"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("office_phone"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("feature_info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("birthday"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("creator_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_keyperson"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("giveup_reason"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data_source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   from_unixtime"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("created_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" created_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   from_unixtime"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_modified"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" last_modified"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_modified_user_id   \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n   contact c  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("exists")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n         contact_branch cb  \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n         branch_user bu        \n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v("  cb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("branch_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("branch_id        \n            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n               "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("      \n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n            org_emp_info oei           \n               "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v("  oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("user_id           \n               "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("node_left "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2875")]),s._v("           \n               "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("node_right "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10802")]),s._v("           \n               "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("org_category "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("      \n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n            c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("contact_id    \n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    \n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v("\n      c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("created_time "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("desc")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n")])])]),a("p",[s._v("验证一下效果 预计在1ms内，提升了13000多倍！")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.00")]),s._v(" sec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),a("p",[s._v("本以为至此大工告成，但我们在前面的分析中漏了一个细节，先排序再join和先join再排序理论上开销是一样的，为何提升这么多是因为有一个limit！大致执行过程是：mysql先按索引排序得到前10条记录，然后再去join过滤，当发现不够10条的时候，再次去10条，再次join，这显然在内层join过滤的数据非常多的时候，将是灾难的，极端情况，内层一条数据都找不到，mysql还傻乎乎的每次取10条，几乎遍历了这个数据表！")]),s._v(" "),a("p",[s._v("用不同参数的SQL试验下：")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n   sql_no_cache   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("position"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("phone"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("office_phone"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("feature_info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("birthday"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("creator_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_keyperson"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("giveup_reason"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data_source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   from_unixtime"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("created_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" created_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   from_unixtime"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_modified"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" last_modified"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_modified_user_id    \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n   contact c   \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("exists")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("        \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n         contact_branch cb         \n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n         branch_user bu                     \n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v("  cb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("branch_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("branch_id                     \n            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n               "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                \n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v("\n            org_emp_info oei                           \n               "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v("  oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("user_id                           \n               "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("node_left "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2875")]),s._v("                           \n               "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("node_right "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2875")]),s._v("                           \n               "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" oei"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("org_category "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("                \n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n            c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("contact_id           \n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("        \n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v("\n      c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("created_time "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("desc")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nEmpty "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" min "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("18.99")]),s._v(" sec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])])]),a("p",[s._v("2 min 18.99 sec！比之前的情况还糟糕很多。由于mysql的nested loop机制，遇到这种情况，基本是无法优化的。这条语句最终也只能交给应用系统去优化自己的逻辑了。")]),s._v(" "),a("p",[a("strong",[s._v("通过这个例子我们可以看到，并不是所有语句都能优化，而往往我们优化时，由于SQL用例回归时落掉一些极端情况，会造成比原来还严重的后果。所以，第一：不要指望所有语句都能通过SQL优化，第二：不要过于自信，只针对具体case来优化，而忽略了更复杂的情况。")])]),s._v(" "),a("h3",{attrs:{id:"_3-4-联合索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-联合索引"}},[s._v("#")]),s._v(" 3.4 联合索引")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v("\n   task \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" \n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" operator_id"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20839")]),s._v(" \n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" operate_time"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1371169729")]),s._v(" \n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" operate_time"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1371174603")]),s._v(" \n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("type")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  \n")])])]),a("p",[s._v("错误方式：")]),s._v(" "),a("p",[s._v("给每个字段都加上索引。")]),s._v(" "),a("p",[s._v("正确方式：")]),s._v(" "),a("p",[s._v("根据最左匹配原则。对 status、operator_id、type、operate_time的建联合索引，其中status、operator_id、type的顺序可以颠倒，operate_time放在最后")]),s._v(" "),a("h2",{attrs:{id:"参考文章"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[s._v("#")]),s._v(" 参考文章")]),s._v(" "),a("p",[a("a",{attrs:{href:"https://pdai.tech/md/db/sql-mysql/sql-mysql-index-improve-mt.html",target:"_blank",rel:"noopener noreferrer"}},[a("strong",[s._v("大厂实践 - 美团: MySQL索引原理及慢查询优化")]),a("OutboundLink")],1)])])}),[],!1,null,null,null);t.default=e.exports}}]);