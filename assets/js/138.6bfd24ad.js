(window.webpackJsonp=window.webpackJsonp||[]).push([[138],{511:function(s,a,t){"use strict";t.r(a);var e=t(26),n=Object(e.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"uniq去重命令"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#uniq去重命令"}},[s._v("#")]),s._v(" uniq去重命令")]),s._v(" "),t("h2",{attrs:{id:"_1-简介"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-简介"}},[s._v("#")]),s._v(" 1 简介")]),s._v(" "),t("p",[s._v("uniq命令可以去除排序过的文件中的重复行")]),s._v(" "),t("blockquote",[t("p",[s._v("因此uniq经常和sort合用。也就是说，为了使uniq起作用，所有的重复行必须是相邻的。")])]),s._v(" "),t("h2",{attrs:{id:"_2-简介"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-简介"}},[s._v("#")]),s._v(" 2 简介")]),s._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[s._v("uniq")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("-icu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n选项与参数：\n-i   ：忽略大小写字符的不同；\n-c  ：进行计数\n-u  ：只显示唯一的行\n")])])]),t("h2",{attrs:{id:"_3-uniq-使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-uniq-使用"}},[s._v("#")]),s._v(" 3 uniq 使用")]),s._v(" "),t("p",[s._v("testfile的内容如下：")]),s._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# cat testfile")]),s._v("\nhello\nworld\nfriend\nhello\nworld\nhello\n")])])]),t("p",[s._v("直接删除未经排序的文件，将会发现没有任何行被删除:")]),s._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#uniq testfile  ")]),s._v("\nhello\nworld\nfriend\nhello\nworld\nhello\n")])])]),t("p",[s._v("排序文件，默认是去重:")]),s._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#cat words | sort |uniq")]),s._v("\nfriend\nhello\nworld\n")])])]),t("p",[s._v("排序之后删除了重复行，同时在行首位置输出该行重复的次数:")]),s._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sort testfile | uniq -c")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" friend\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" hello\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" world\n")])])]),t("p",[s._v("仅显示存在重复的行，并在行首显示该行重复的次数:")]),s._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sort testfile | uniq -dc")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" hello\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" world\n")])])]),t("p",[s._v("仅显示不重复的行:")]),s._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sort testfile | uniq -u")]),s._v("\nfriend \n")])])])])}),[],!1,null,null,null);a.default=n.exports}}]);